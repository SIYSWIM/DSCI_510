{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "add2e43c",
   "metadata": {},
   "source": [
    "# Lab 8\n",
    "---\n",
    "Hello and welcome to Lab 8.\n",
    "\n",
    "__Guidelines:__\n",
    "\n",
    "- Please write and submit the two programs below by the deadline: Monday, March 27, at 6:00pm Pacific time\n",
    "\n",
    "- You must complete the assignments individually. If you have trouble completing the assignment, please let one of the teaching assistants (TAs) know, during the lab or their office hours. They will help and guide you, but they will not write code for you and no one else should :) !!!  \n",
    "\n",
    "- You have to fill in the code in this notebook and upload it back to Blackboard for submission. Please remember to rename your file as \"Lab8_[YOUR FIRSTNAME]_[YOUR LASTNAME].ipynb\" (e.g. Lab8_George_Washington.ipynb).\n",
    "\n",
    "- You may look up resources online like python docs and stackoverflow. You may look up topics, but not the questions themselves.\n",
    "\n",
    "- You can submit only one time. Your grade will be based on this submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b938d6f",
   "metadata": {},
   "source": [
    "# Q1. [10 points] \n",
    "---\n",
    "### API: Gender prediction\n",
    "\n",
    "Write a function _gender_based_on_name()_ that will predict whether a given name is male or female.<br>\n",
    "Use an API.<br>\n",
    "See example presented in class on March 22, 2023.<br>\n",
    "Call ```strip()``` over the name for added robustness.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "508dd283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import requests\n",
    "\n",
    "def gender_based_on_name(name: str) -> Optional[str]:\n",
    "    input_name = name.strip()\n",
    "    url = f'https://api.genderize.io?name={input_name}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    output = data['gender']\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0593e12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female\n",
      "male\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# open test\n",
    "\n",
    "print(gender_based_on_name('Mary'))         # should print 'female'\n",
    "print(gender_based_on_name('John'))         # should print 'male'\n",
    "print(gender_based_on_name('NoSuchName'))   # should print None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719163e2",
   "metadata": {},
   "source": [
    "# Q2 [10 points]\n",
    "\n",
    "### API: Airport weather\n",
    "\n",
    "For this question, we will be using requests library to request\n",
    "```api.weather.gov``` to get an airport's weather information. Based on that, you have to determine whether or not the weather at the airport is cloudy or not.  \n",
    "\n",
    "*How to decide whether the airport is cloudy or not?*  \n",
    "We check if the ```shortForecast``` field has the word ___cloudy___ for the next time period. Forecasts such as _mostly cloudy_ or _partly cloudy_ count as cloudy. It will be a two-step process to obtain the value for ```sortForecast```: the first API request will include a URL that, when called, contains the ```shortForecast``` that we are after.\n",
    "\n",
    "Input: String(Airport name)  \n",
    "Output: Boolean(True if cloudy, False otherwise)  \n",
    "\n",
    "FAQs:  \n",
    "Q. What link should I use for the requests.get() function?  \n",
    "A. Link would look something like this -> https://api.weather.gov/points/ ```<Latitude value>,<Longitude value>```   \n",
    "An Example would be: https://api.weather.gov/points/39.7456,-97.0892\n",
    "\n",
    "Q. I got something after requesting, but, I am not sure, what it is.  \n",
    "A. You received a response object. You can call .json() to it and see what is there. (See ```json.dumps()```)  \n",
    "\n",
    "Q. How do I get information from this json?  \n",
    "A. For getting info from that, as taught in the class, you can simply index them by using keys that you want after assessing the json.  \n",
    "\n",
    "Q. Okay, I indexed the json using the keys and I get some list out of it. What is that?  \n",
    "A. That list is the forecast for the next hours. You'll need this information for making the decision that is required in the question. Also, what you are getting in the list is a dict. **Make sure you understand what you are dealing with at each point.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3554e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_airport_info() -> dict:\n",
    "    \"\"\"This function builds a dictionary mapping airport names to the latitude and longitude of the airports, \n",
    "    based on file Airports.txt that has been provided to you.\"\"\"\n",
    "    airports = dict()\n",
    "    with open('Airports.txt', encoding='utf8') as file:\n",
    "        for line in file:\n",
    "            airport_name, coordinates = line.split('\\t')[1], line.split('\\t')[3].split(',')\n",
    "            long, lat = float(coordinates[0][1:]), float(coordinates[1][1:-2])\n",
    "            airports[airport_name] = (lat, long)\n",
    "    return airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6bdb41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from typing import Optional\n",
    "\n",
    "def cloudy_airport(airport_name: str) -> Optional[bool]:\n",
    "    ## access to the dictionary\n",
    "    airport_dict = get_airport_info()\n",
    "    ## get the coordinates and round it as the regular format in a website link\n",
    "    coordinates = list(airport_dict[airport_name])\n",
    "    long = round(float(coordinates[0]),4)\n",
    "    lat = round(float(coordinates[1]),4)\n",
    "    url_airport = f'https://api.weather.gov/points/{long},{lat}'\n",
    "    ## access to the website\n",
    "    repsonse_airport = requests.get(url_airport)\n",
    "    data_airport = repsonse_airport.json()\n",
    "    ## first go to the forecast link\n",
    "    url_weather = data_airport['properties']['forecastHourly']\n",
    "    response_weather = requests.get(url_weather)\n",
    "    data_weather = response_weather.json()\n",
    "    ## find the next-hour weather\n",
    "    next_hour_weather = data_weather['properties']['periods'][0]\n",
    "    weather_reported = next_hour_weather['shortForecast']\n",
    "    if \"cloudy\" in weather_reported:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9527ec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los Angeles County Sheriff's Department Heliport is not cloudy.\n"
     ]
    }
   ],
   "source": [
    "# open test\n",
    "\n",
    "airports = [\"Los Angeles County Sheriff's Department Heliport\"]\n",
    "for airport in airports:\n",
    "    cloudy = cloudy_airport(airport)\n",
    "    if cloudy is None:\n",
    "        print(f\"No info available for {airport}.\")\n",
    "    elif cloudy:\n",
    "        print(f\"{airport} is cloudy.\")\n",
    "    else:\n",
    "        print(f\"{airport} is not cloudy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f7bbe",
   "metadata": {},
   "source": [
    "# Q3 [10 points]\n",
    "\n",
    "### Webscraping: Newspaper\n",
    "\n",
    "For this question, we will scrape the website \"https://www.dailynews.com\".  \n",
    "\n",
    "For a given keyword, e.g. _COVID_, return all news headlines (and their links) on the website above that contain the keyword in the headline. Specifically, return a list of tuples where the first component is the link to the article and where the second component is the headline text.\n",
    "\n",
    "* Searches for the keyword in a headlines should be case-insensitive, e.g. when searching for _marathon_, you should return headlines containing _Marathon_ (capitalized).\n",
    "* Call ```strip()``` over the link and the headline text, so that it is more readable.  \n",
    "* Consider using BeautifulSoup and its .prettify() feature, which might better guide your web-scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a9bb7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from typing import List, Tuple\n",
    "\n",
    "def get_news_of(keyword: str) -> List[Tuple[str, str]]:\n",
    "    \n",
    "    ## make a list for news\n",
    "    news_list = []\n",
    "\n",
    "    url_news = \"https://www.dailynews.com/\"\n",
    "    response_news = requests.get(url_news)\n",
    "    data_news = BeautifulSoup(response_news.text, 'html.parser')\n",
    "    ## exclude the trending\n",
    "    news_content = data_news.find('div',{'class':'content-area'})\n",
    "    ## only the content area\n",
    "    article = news_content.find_all('a',{'class':'article-title'})\n",
    "    for news in article:\n",
    "        if news['title'] and news['href']:\n",
    "            ## check whether the headline contains the keyword\n",
    "            headline = news['title'].strip()\n",
    "            if keyword.lower() in headline.lower():\n",
    "                link = news['href'].strip()\n",
    "                ## a duplicated headline may exist\n",
    "                if tuple((link, headline)) not in news_list:\n",
    "                    news_list.append(tuple((link, headline)))\n",
    "    return news_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f7421f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https://www.dailynews.com/2023/03/26/indigenous-tribes-work-with-swedish-and-csun-scholars-to-thrive-in-california/', 'Indigenous tribes work with Swedish and CSUN scholars to thrive in California'), ('https://www.dailynews.com/2023/03/25/what-you-need-to-know-about-growing-berries-in-southern-california/', 'What you need to know about growing berries in Southern California'), ('https://www.dailynews.com/2023/03/24/in-wake-of-southern-californias-wet-winter-potholes-pose-a-perilous-problem/', 'In wake of Southern California’s wet winter, potholes pose a perilous problem'), ('https://www.dailynews.com/2023/03/14/another-storm-hits-southern-california-with-more-rain-possible-over-the-weekend/', 'Another storm hits Southern California, with more rain possible over the weekend'), ('https://www.dailynews.com/2023/02/27/southern-californias-mountain-towns-remain-buried-under-snow-with-more-on-the-way/', 'Southern California’s mountain towns remain buried under snow with more on the way'), ('https://www.dailynews.com/2023/02/25/grapevine-highway-14-closed-saturday-as-storm-pounds-southern-california/', 'Snow falls in cities, lightning strikes at beaches as historic storm pounds Southern California'), ('https://www.dailynews.com/2023/03/26/for-proposition-13s-sake-lets-keep-the-elected-california-board-of-equalization/', 'For Proposition 13’s sake, let’s keep the elected California Board of Equalization'), ('https://www.dailynews.com/2023/03/26/california-can-solve-homeless-crisis/', 'California can solve the homelessness crisis, it just can’t keep doing more of the same')]\n",
      "[('https://www.dailynews.com/2023/03/26/wealthy-educated-youre-primed-to-live-through-covid-19/', 'Wealthy? Educated? You’re primed to live through COVID-19')]\n"
     ]
    }
   ],
   "source": [
    "# open test\n",
    "print(get_news_of('California'))\n",
    "print(get_news_of('Covid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cd505b",
   "metadata": {},
   "source": [
    "# Bonus question [5 points]\n",
    "\n",
    "### Regex: Data cleaning\n",
    "\n",
    "Check this out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f297b5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1, s2 = \"Alexa\", \"Аlexa\"\n",
    "s1 == s2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db70f0c6",
   "metadata": {},
   "source": [
    "Surprise? &nbsp; Let's investigate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cddf632b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A  U+0041  LATIN CAPITAL LETTER A\n",
      "l  U+006C  LATIN SMALL LETTER L\n",
      "e  U+0065  LATIN SMALL LETTER E\n",
      "x  U+0078  LATIN SMALL LETTER X\n",
      "a  U+0061  LATIN SMALL LETTER A\n",
      "А  U+0410  CYRILLIC CAPITAL LETTER A\n",
      "l  U+006C  LATIN SMALL LETTER L\n",
      "e  U+0065  LATIN SMALL LETTER E\n",
      "x  U+0078  LATIN SMALL LETTER X\n",
      "a  U+0061  LATIN SMALL LETTER A\n"
     ]
    }
   ],
   "source": [
    "import unicodedata as ud\n",
    "\n",
    "def print_unicode_names_of_letters(s: str) -> None:\n",
    "    for letter in s:\n",
    "        print(f\"{letter}  U+{ord(letter):04X}  {ud.name(letter)}\")\n",
    "\n",
    "print_unicode_names_of_letters(s1 + s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa435da2",
   "metadata": {},
   "source": [
    "So it turns out there are look-alike characters between various scripts.<p>\n",
    "__Task:__ Write a function _clean_latin_text_ that checks and cleans a line of text as follows.\n",
    "If a word inside the line contains both Latin and Cyrillic characters and all Cyrillic characters in that word have look-alike Latin characters, as defined in the _cyr2lat_ dictionary below, map all Cyrillic characters in that word to their Latin counterparts. If a word contains no Latin characters, or if some Cyrillic characters do not have any Latin counterparts, don't change any part of the word, as it is not clear that it was really meant to be a Latin-script word."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cfbbb0bc",
   "metadata": {},
   "source": [
    "if both latin and cyrillic inside, and all cyrillic look-like latin -- output latin\n",
    "if no latin or if the cyrillic not look-like lation -- original word\n",
    "cyrillic: ord between U+0400 to U+04FF\n",
    "latin 0041 to 024F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "459d9325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "cyr2lat = {'Ѕ':'S', 'А':'A', 'В':'B', 'Е':'E', 'К':'K', 'М':'M', 'Н':'H', 'О':'O', 'Р':'P', \n",
    "           'С':'C', 'Т':'T', 'Х':'X', 'Ԛ':'Q', 'Ԝ':'W', 'а':'a', 'е':'e', 'о':'o', 'р':'p', \n",
    "           'с':'c', 'у':'y', 'х':'x', 'ѕ':'s', 'і':'i', 'ј':'j', 'ԛ':'q', 'ԝ':'w'}\n",
    "\n",
    "def clean_latin_text(s: str) -> str:\n",
    "    word_list = s.split()\n",
    "    cleaned_text = []\n",
    "    cleaned_word = []\n",
    "    ## check whether a word contains both Latin and Cyrillic\n",
    "    pattern = r'(\\p{Latin}.*\\p{Cyrillic}|\\p{Cyrillic}.*\\p{Latin})'\n",
    "    for word in word_list:\n",
    "        if regex.search(pattern, word):\n",
    "            ## change the cyrillic word if look-like Latin\n",
    "            for letter in word:\n",
    "                if letter in cyr2lat.keys():\n",
    "                    letter = cyr2lat[letter]\n",
    "                    cleaned_word.append(letter)\n",
    "                ## else, keep the original\n",
    "                else:\n",
    "                    letter = letter\n",
    "                    cleaned_word.append(letter)\n",
    "            ## join the letter together\n",
    "            word = ''.join(cleaned_word)\n",
    "        else:\n",
    "            word = word\n",
    "        cleaned_text.append(word)\n",
    "    output = ' '.join(cleaned_text)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc169c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexander; слава і воля.\n",
      "A  U+0041  LATIN CAPITAL LETTER A\n",
      "l  U+006C  LATIN SMALL LETTER L\n",
      "e  U+0065  LATIN SMALL LETTER E\n",
      "x  U+0078  LATIN SMALL LETTER X\n",
      "a  U+0061  LATIN SMALL LETTER A\n",
      "n  U+006E  LATIN SMALL LETTER N\n",
      "d  U+0064  LATIN SMALL LETTER D\n",
      "e  U+0065  LATIN SMALL LETTER E\n",
      "r  U+0072  LATIN SMALL LETTER R\n",
      ";  U+003B  SEMICOLON\n",
      "   U+0020  SPACE\n",
      "с  U+0441  CYRILLIC SMALL LETTER ES\n",
      "л  U+043B  CYRILLIC SMALL LETTER EL\n",
      "а  U+0430  CYRILLIC SMALL LETTER A\n",
      "в  U+0432  CYRILLIC SMALL LETTER VE\n",
      "а  U+0430  CYRILLIC SMALL LETTER A\n",
      "   U+0020  SPACE\n",
      "і  U+0456  CYRILLIC SMALL LETTER BYELORUSSIAN-UKRAINIAN I\n",
      "   U+0020  SPACE\n",
      "в  U+0432  CYRILLIC SMALL LETTER VE\n",
      "о  U+043E  CYRILLIC SMALL LETTER O\n",
      "л  U+043B  CYRILLIC SMALL LETTER EL\n",
      "я  U+044F  CYRILLIC SMALL LETTER YA\n",
      ".  U+002E  FULL STOP\n"
     ]
    }
   ],
   "source": [
    "# open test\n",
    "\n",
    "print(clean_latin_text(\"Аlехаndеr; слава і воля.\"))\n",
    "print_unicode_names_of_letters(clean_latin_text(\"Аlехаndеr; слава і воля.\"))\n",
    "# Should yield: Alexander; слава і воля.  (Use print_unicode_names_of_letters() as needed.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
